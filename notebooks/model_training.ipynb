{"cells":[{"cell_type":"markdown","metadata":{"id":"YIeBggbihZkZ"},"source":["# NYC Airbnb Price Prediction - fastai model training\n","\n","Use dataset published by Kaggle - https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data - to train a simple XGBoost model to predict prices for Airbnb properties.\n","\n","This notebook contains the code to train the model from the dataset prepared in the [data cleanup](https://github.com/ryanmark1867/fastai_basics/blob/master/notebooks/data_cleanup.ipynb) notebook. It is adapted from the [Keras model training notebook](https://github.com/ryanmark1867/deep_learning_basics/blob/master/notebooks/model_training.ipynb) trained on the same dataset.\n"]},{"cell_type":"markdown","metadata":{"id":"DlRfewg3hZkg"},"source":["# Links to key parts of the notebook <a name='linkanchor' />\n","<a href=#ingestdash>Ingest data</a>\n","\n","<a href=#buildpipe>Build pipeline</a>\n","\n","<a href=#modelfit>Define and fit model</a>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"sEt7qZr7hZkh"},"source":["# Common imports and global variable definitions"]},{"cell_type":"code","source":["\n","''' check to see if the notebook is being run in Colab, and if so, set the current directory appropriately'''\n","if 'google.colab' in str(get_ipython()):\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  %cd /content/drive/MyDrive/machine_learning_tabular_book/code/fastai_basics/notebooks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gH8To-DKhoMZ","executionInfo":{"status":"ok","timestamp":1666484305053,"user_tz":240,"elapsed":2626,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"dd63ea6f-f7cc-4888-bd5d-23c5cdeb9070"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/machine_learning_tabular_book/code/fastai_basics/notebooks\n"]}]},{"cell_type":"code","source":["import time\n","start_time = time.time()"],"metadata":{"id":"sFs8nj9ynE4S","executionInfo":{"status":"ok","timestamp":1666484305056,"user_tz":240,"elapsed":24,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# fastai imports\n","!pip install -Uqq fastbook\n","import fastbook\n","from fastbook import *\n","from fastai.tabular.all import *"],"metadata":{"id":"uP7LvxOo0BrD","executionInfo":{"status":"ok","timestamp":1666484311235,"user_tz":240,"elapsed":6202,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"qMOg5J2MhZki","executionInfo":{"status":"ok","timestamp":1666484311267,"user_tz":240,"elapsed":145,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"outputs":[],"source":["# common imports\n","import zipfile\n","import pandas as pd\n","import numpy as np\n","import time\n","import seaborn as sns\n","from matplotlib import pyplot\n","# import datetime, timedelta\n","import datetime\n","import pydotplus\n","from datetime import datetime, timedelta\n","from datetime import date\n","from dateutil import relativedelta\n","from io import StringIO\n","import pandas as pd\n","import pickle\n","from pickle import dump\n","from pickle import load\n","from sklearn.base import BaseEstimator\n","from sklearn.base import TransformerMixin\n","# DSX code to import uploaded documents\n","from io import StringIO\n","import requests\n","import json\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import os\n","import yaml\n","import math\n","import sys\n","from subprocess import check_output\n","from IPython.display import display\n","#model libraries\n","\n","#from datetime import date\n","from sklearn import metrics\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cPDRPSYRhZkp","executionInfo":{"status":"ok","timestamp":1666484311269,"user_tz":240,"elapsed":141,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"fd0e1d94-f065-4708-e07d-4b31d821b5fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["current directory is: /content/drive/MyDrive/machine_learning_tabular_book/code/fastai_basics/notebooks\n","path_to_yaml /content/drive/MyDrive/machine_learning_tabular_book/code/fastai_basics/notebooks/model_training_config.yml\n"]}],"source":["# load config file\n","current_path = os.getcwd()\n","print(\"current directory is: \"+current_path)\n","\n","path_to_yaml = os.path.join(current_path, 'model_training_config.yml')\n","print(\"path_to_yaml \"+path_to_yaml)\n","try:\n","    with open (path_to_yaml, 'r') as c_file:\n","        config = yaml.safe_load(c_file)\n","except Exception as e:\n","    print('Error reading the config file')\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ukTsqXUAhZkr","executionInfo":{"status":"ok","timestamp":1666484311271,"user_tz":240,"elapsed":137,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"f16dcc9d-b5a8-47fa-fa3a-7ca832577c6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["date today 2022-10-23 00:18:29.257179\n"]}],"source":["# load parameters\n","\n","repeatable_run = config['test_parms']['repeatable_run']\n","# fix seeds to get identical results on mulitiple runs\n","if repeatable_run:\n","    from numpy.random import seed\n","    seed(4)\n","    tf.random.set_seed(7)\n","\n","\n","testproportion = config['test_parms']['testproportion'] # proportion of data reserved for test set\n","trainproportion = config['test_parms']['trainproportion'] # proportion of non-test data dedicated to training (vs. validation)\n","get_test_train_acc = config['test_parms']['get_test_train_acc']\n","verboseout = config['general']['verboseout']\n","includetext = config['general']['includetext'] # switch to determine whether text columns are included in the model\n","save_model_plot = config['general']['save_model_plot'] # switch to determine whether to generate plot with plot_model\n","tensorboard_callback = config['general']['tensorboard_callback'] # switch to determine if tensorboard callback defined\n","\n","presaved = config['general']['presaved']\n","savemodel = config['general']['savemodel']\n","picklemodel = config['general']['picklemodel']\n","hctextmax = config['general']['hctextmax']\n","maxwords = config['general']['maxwords']\n","textmax = config['general']['textmax']\n","\n","targetthresh = config['general']['targetthresh']\n","targetcontinuous = config['general']['targetcontinuous']\n","target_col = config['general']['target_col']\n","\n","#time of day thresholds\n","time_of_day = {'overnight':{'start':0,'end':5},'morning_rush':{'start':5,'end':10},\n","              'midday':{'start':10,'end':15},'aft_rush':{'start':15,'end':19},'evening':{'start':19,'end':24}}\n","\n","\n","\n","emptythresh = config['general']['emptythresh']\n","zero_weight = config['general']['zero_weight']\n","one_weight = config['general']['one_weight']\n","one_weight_offset = config['general']['one_weight_offset']\n","patience_threshold = config['general']['patience_threshold']\n","\n","\n","# modifier for saved model elements\n","modifier = config['general']['modifier']\n","\n","# control whether training controlled by early stop\n","early_stop = True\n","\n","# default hyperparameter values\n","learning_rate = config['hyperparameters']['learning_rate']\n","dropout_rate = config['hyperparameters']['dropout_rate']\n","l2_lambda = config['hyperparameters']['l2_lambda']\n","loss_func = config['hyperparameters']['loss_func']\n","output_activation = config['hyperparameters']['output_activation']\n","batch_size = config['hyperparameters']['batch_size']\n","epochs = config['hyperparameters']['epochs']\n","\n","# date values\n","date_today = datetime.now()\n","print(\"date today\",date_today)\n","\n","# pickled original dataset and post-preprocessing dataset\n","pickled_data_file = config['general']['pickled_data_file']\n","pickled_dataframe = config['general']['pickled_dataframe']\n","\n","# experiment parameter\n","\n","current_experiment = config['test_parms']['current_experiment']\n","\n","# load lists of column categories\n","collist = config['categorical']\n","textcols = config['text']\n","continuouscols = config['continuous']\n","excludefromcolist = config['excluded']"]},{"cell_type":"markdown","metadata":{"id":"LHOm49gThZku"},"source":["# Helper functions"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"gID1ffP6hZkw","executionInfo":{"status":"ok","timestamp":1666484311275,"user_tz":240,"elapsed":131,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"outputs":[],"source":["# time_of_day = {'overnight':{'start':0,'end':5},'morning_rush':{'start':5,'end':10},\n","#              'midday':{'start':10,'end':15},'aft_rush':{'start':15,'end':19},'evening':{'start':19,'end':23}}\n","\n","\n","def get_time(hour):\n","    for tod in time_of_day:\n","        if (hour >= time_of_day[tod]['start']) and (hour < time_of_day[tod]['end']):\n","            tod_out = tod\n","    return(tod_out)\n","\n","def weekend_time(day, tod):\n","    if (day=='Saturday') or (day=='Sunday'):\n","        return('w'+tod)\n","    else:\n","        return(tod)\n","\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"f7O0zkMphZky","executionInfo":{"status":"ok","timestamp":1666484311277,"user_tz":240,"elapsed":131,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"outputs":[],"source":["# get the paths required\n","\n","def get_path():\n","    '''get the path for data files\n","\n","    Returns:\n","        path: path for data files\n","    '''\n","    rawpath = os.getcwd()\n","    # data is in a directory called \"data\" that is a sibling to the directory containing the notebook\n","    path = os.path.abspath(os.path.join(rawpath, '..', 'data'))\n","    return(path)\n","\n","def get_pipeline_path():\n","    '''get the path for data files\n","    \n","    Returns:\n","        path: path for pipeline files\n","    '''\n","    rawpath = os.getcwd()\n","    # data is in a directory called \"data\" that is a sibling to the directory containing the notebook\n","    path = os.path.abspath(os.path.join(rawpath, '..', 'pipelines'))\n","    return(path)\n","\n","def get_model_path():\n","    '''get the path for data files\n","    \n","    Returns:\n","        path: path for model files\n","    '''\n","    rawpath = os.getcwd()\n","    # data is in a directory called \"data\" that is a sibling to the directory containing the notebook\n","    path = os.path.abspath(os.path.join(rawpath, '..', 'models'))\n","    return(path)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"UHr7ftVJhZkz","executionInfo":{"status":"ok","timestamp":1666484311278,"user_tz":240,"elapsed":130,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"outputs":[],"source":["def set_experiment_parameters(experiment_number, count_no_delay, count_delay):\n","    ''' set the appropriate parameters for the experiment \n","    Args:\n","        experiment_number: filename containing config parameters\n","        count_no_delay: count of negative outcomes in the dataset\n","        count_delay: count of positive outcomes in the dataset\n","\n","    Returns:\n","        early_stop: whether the experiment includes an early stop callback\n","        one_weight: weight applied to positive outcomes\n","        epochs: number of epochs in the experiment\n","        es_monitor: performance measurement tracked in callbacks\n","        es_mod: direction of performance being tracked in callbacks\n","    \n","    '''\n","    print(\"setting parameters for experiment \", experiment_number)\n","    # default settings for early stopping:\n","    es_monitor = \"val_loss\"\n","    es_mode = \"min\"\n","    if experiment_number == 0:\n","        #\n","        early_stop = False\n","        #\n","        one_weight = 1.0\n","        #\n","        epochs = 1\n","    elif experiment_number == 9:\n","        #\n","        early_stop = True\n","        es_monitor=\"val_accuracy\"\n","        es_mode = \"max\"\n","        #\n","        one_weight = (count_no_delay/count_delay) + one_weight_offset\n","        #\n","        get_test_train_acc = False\n","        #\n","        epochs = 20    \n","    elif experiment_number == 1:\n","        #\n","        early_stop = False\n","        #\n","        one_weight = 1.0\n","        #\n","        epochs = 10\n","    elif experiment_number == 2:\n","        #\n","        early_stop = False\n","        #\n","        one_weight = 1.0\n","        #\n","        epochs = 50\n","    elif experiment_number == 3:\n","        #\n","        early_stop = False\n","        #\n","        one_weight = (count_no_delay/count_delay) + one_weight_offset\n","        #\n","        epochs = 50\n","    elif experiment_number == 4:\n","        #\n","        early_stop = True\n","        es_monitor = \"val_loss\"\n","        es_mode = \"min\"\n","        #\n","        one_weight = (count_no_delay/count_delay) + one_weight_offset\n","        #\n","        epochs = 50\n","    elif experiment_number == 5:\n","        #\n","        early_stop = True\n","        # if early stopping fails because the level of TensorFlow/Python, comment out the following\n","        # line and uncomment the subsequent if statement\n","        es_monitor=\"val_accuracy\"\n","        '''\n","        if sys.version_info >= (3,7):\n","            es_monitor=\"val_accuracy\"\n","        else:\n","            es_monitor = \"val_acc\"\n","        '''\n","        es_mode = \"max\"\n","        #\n","        one_weight = (count_no_delay/count_delay) + one_weight_offset\n","        #\n","        epochs = 50\n","    else:\n","        early_stop = True\n","    return(early_stop, one_weight, epochs,es_monitor,es_mode)\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"g-Qgt5J-hZk0"},"source":["# Ingest data and create refactored dataframe <a name='ingestdash' />\n","- Ingest data for route information and delay information\n","- Create refactored dataframe with one row per route / direction / timeslot combination\n","\n","\n","<a href=#linkanchor>Back to link list</a>"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"DgI5ZiUShZk1","executionInfo":{"status":"ok","timestamp":1666484311281,"user_tz":240,"elapsed":132,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"outputs":[],"source":["def ingest_data(path):\n","    '''load list of valid routes and directions into dataframe\n","    Args:\n","        path: path for data files\n","    \n","    Returns:\n","        merged_data: dataframe loaded from pickle file\n","    '''\n","    file_name = os.path.join(path,pickled_dataframe)\n","    merged_data = pd.read_pickle(file_name)\n","    merged_data.head()\n","    return(merged_data)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"eUn9rPCdhZk1","executionInfo":{"status":"ok","timestamp":1666484311282,"user_tz":240,"elapsed":132,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"outputs":[],"source":["def prep_merged_data(merged_data,target_col):\n","    '''add derived columns to merged_data dataframe\n","    Args:\n","        merged_data: input dataframe\n","        target_col: column that is the target\n","    \n","    Returns:\n","        merged_data: dataframe with derived columns added\n","    '''\n","    if targetcontinuous:\n","        merged_data['target'] = merged_data[target_col]\n","    else:\n","        merged_data['target'] = np.where(merged_data[target_col] >= merged_data[target_col].mean(), 1, 0 )\n","    return(merged_data)"]},{"cell_type":"markdown","metadata":{"id":"w4-DJIY8hZk2"},"source":["# Master Prep Cell\n","Contains calls to functions to load data, prep input dataframes, and create refactored dataframe"]},{"cell_type":"code","execution_count":12,"metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/","height":139},"id":"P_unjf8hhZk3","executionInfo":{"status":"ok","timestamp":1666484311284,"user_tz":240,"elapsed":132,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"76a8d3de-28e4-4717-ed5d-c343bd8a26ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["path is /content/drive/MyDrive/machine_learning_tabular_book/code/fastai_basics/data\n"]},{"output_type":"execute_result","data":{"text/plain":["'\\nprint(\"shape of pre refactored dataset\", merged_data.shape)\\n#merged_data[\\'year\\'].value_counts()\\n#merged_data.groupby([\\'Route\\',\\'Direction\\']).size().reset_index().rename(columns={0:\\'count\\'}).tail(50)\\n# create refactored dataframe with one row for each route / direction / timeslot combination\\nprint(\"shape of refactored dataset\", merged_data.shape)\\ncount_no_delay = merged_data[merged_data[\\'target\\']==0].shape[0]\\ncount_delay = merged_data[merged_data[\\'target\\']==1].shape[0]\\nprint(\"count under mean \",count_no_delay)\\nprint(\"count over mean \",count_delay)\\n# define parameters for the current experiment\\nexperiment_number = current_experiment\\nearly_stop, one_weight, epochs,es_monitor,es_mode = set_experiment_parameters(experiment_number, count_no_delay, count_delay)\\nprint(\"early_stop is \",early_stop)\\nprint(\"one_weight is \",one_weight)\\nprint(\"epochs is \",epochs)\\nprint(\"es_monitor is \",es_monitor)\\nprint(\"es_mode is \",es_mode)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}],"source":["# master calls\n","\n","path = get_path()\n","print(\"path is\",path)\n","# load route direction and delay data datframes\n","merged_data = ingest_data(path)\n","merged_data = prep_merged_data(merged_data,target_col)\n","\n","\n","'''\n","print(\"shape of pre refactored dataset\", merged_data.shape)\n","#merged_data['year'].value_counts()\n","#merged_data.groupby(['Route','Direction']).size().reset_index().rename(columns={0:'count'}).tail(50)\n","# create refactored dataframe with one row for each route / direction / timeslot combination\n","print(\"shape of refactored dataset\", merged_data.shape)\n","count_no_delay = merged_data[merged_data['target']==0].shape[0]\n","count_delay = merged_data[merged_data['target']==1].shape[0]\n","print(\"count under mean \",count_no_delay)\n","print(\"count over mean \",count_delay)\n","# define parameters for the current experiment\n","experiment_number = current_experiment\n","early_stop, one_weight, epochs,es_monitor,es_mode = set_experiment_parameters(experiment_number, count_no_delay, count_delay)\n","print(\"early_stop is \",early_stop)\n","print(\"one_weight is \",one_weight)\n","print(\"epochs is \",epochs)\n","print(\"es_monitor is \",es_monitor)\n","print(\"es_mode is \",es_mode)\n","'''"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6xpjyG_hhZk3","executionInfo":{"status":"ok","timestamp":1666484311286,"user_tz":240,"elapsed":121,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"f99a7384-89f4-4683-bf11-63b462854dcf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(48895, 18)"]},"metadata":{},"execution_count":13}],"source":["merged_data.shape"]},{"cell_type":"code","source":["merged_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":478},"id":"g7rUQJH-7efD","executionInfo":{"status":"ok","timestamp":1666484311288,"user_tz":240,"elapsed":116,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"8302c44a-efc4-411e-b9fd-e1f7f3ef3287"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     id                                              name  host_id  \\\n","0  2539                Clean & quiet apt home by the park     2787   \n","1  2595                             Skylit Midtown Castle     2845   \n","2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n","3  3831                   Cozy Entire Floor of Brownstone     4869   \n","4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n","\n","     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n","0         John            Brooklyn    Kensington  40.64749  -73.97237   \n","1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n","2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n","3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n","4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n","\n","         room_type  price  minimum_nights  number_of_reviews last_review  \\\n","0     Private room    149               1                  9  2018-10-19   \n","1  Entire home/apt    225               1                 45  2019-05-21   \n","2     Private room    150               3                  0  2019-01-01   \n","3  Entire home/apt     89               1                270  2019-07-05   \n","4  Entire home/apt     80              10                  9  2018-11-19   \n","\n","   reviews_per_month  calculated_host_listings_count  availability_365  \\\n","0               0.21                               6               365   \n","1               0.38                               2               355   \n","2               0.00                               1               365   \n","3               4.64                               1               194   \n","4               0.10                               1                 0   \n","\n","   (latitude, longitude)  target  \n","0  (40.64749, -73.97237)       0  \n","1  (40.75362, -73.98377)       1  \n","2   (40.80902, -73.9419)       0  \n","3  (40.68514, -73.95976)       0  \n","4  (40.79851, -73.94399)       0  "],"text/html":["\n","  <div id=\"df-08a4366a-3850-4aba-97f5-28db1f31496a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>name</th>\n","      <th>host_id</th>\n","      <th>host_name</th>\n","      <th>neighbourhood_group</th>\n","      <th>neighbourhood</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>room_type</th>\n","      <th>price</th>\n","      <th>minimum_nights</th>\n","      <th>number_of_reviews</th>\n","      <th>last_review</th>\n","      <th>reviews_per_month</th>\n","      <th>calculated_host_listings_count</th>\n","      <th>availability_365</th>\n","      <th>(latitude, longitude)</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2539</td>\n","      <td>Clean &amp; quiet apt home by the park</td>\n","      <td>2787</td>\n","      <td>John</td>\n","      <td>Brooklyn</td>\n","      <td>Kensington</td>\n","      <td>40.64749</td>\n","      <td>-73.97237</td>\n","      <td>Private room</td>\n","      <td>149</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>2018-10-19</td>\n","      <td>0.21</td>\n","      <td>6</td>\n","      <td>365</td>\n","      <td>(40.64749, -73.97237)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2595</td>\n","      <td>Skylit Midtown Castle</td>\n","      <td>2845</td>\n","      <td>Jennifer</td>\n","      <td>Manhattan</td>\n","      <td>Midtown</td>\n","      <td>40.75362</td>\n","      <td>-73.98377</td>\n","      <td>Entire home/apt</td>\n","      <td>225</td>\n","      <td>1</td>\n","      <td>45</td>\n","      <td>2019-05-21</td>\n","      <td>0.38</td>\n","      <td>2</td>\n","      <td>355</td>\n","      <td>(40.75362, -73.98377)</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3647</td>\n","      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n","      <td>4632</td>\n","      <td>Elisabeth</td>\n","      <td>Manhattan</td>\n","      <td>Harlem</td>\n","      <td>40.80902</td>\n","      <td>-73.94190</td>\n","      <td>Private room</td>\n","      <td>150</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>2019-01-01</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>365</td>\n","      <td>(40.80902, -73.9419)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3831</td>\n","      <td>Cozy Entire Floor of Brownstone</td>\n","      <td>4869</td>\n","      <td>LisaRoxanne</td>\n","      <td>Brooklyn</td>\n","      <td>Clinton Hill</td>\n","      <td>40.68514</td>\n","      <td>-73.95976</td>\n","      <td>Entire home/apt</td>\n","      <td>89</td>\n","      <td>1</td>\n","      <td>270</td>\n","      <td>2019-07-05</td>\n","      <td>4.64</td>\n","      <td>1</td>\n","      <td>194</td>\n","      <td>(40.68514, -73.95976)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5022</td>\n","      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n","      <td>7192</td>\n","      <td>Laura</td>\n","      <td>Manhattan</td>\n","      <td>East Harlem</td>\n","      <td>40.79851</td>\n","      <td>-73.94399</td>\n","      <td>Entire home/apt</td>\n","      <td>80</td>\n","      <td>10</td>\n","      <td>9</td>\n","      <td>2018-11-19</td>\n","      <td>0.10</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>(40.79851, -73.94399)</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08a4366a-3850-4aba-97f5-28db1f31496a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-08a4366a-3850-4aba-97f5-28db1f31496a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-08a4366a-3850-4aba-97f5-28db1f31496a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"CAz0ZvIghZk4"},"source":["# Define training, validation, and test subsets of the dataset"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"z1WjDwUdhZk4","executionInfo":{"status":"ok","timestamp":1666484311291,"user_tz":240,"elapsed":112,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"outputs":[],"source":["def get_train_validation_test(dataset):\n","    '''get training and test data set\n","    Args:\n","        dataset: input dataframe\n","    \n","    Returns:\n","        dtrain: training subset of dataset\n","        dvalid: validation subset of dataset\n","        dtest: test subset of dataset\n","    '''\n","    train, test = train_test_split(dataset, test_size = testproportion)\n","    dtrain, dvalid = train_test_split(train, random_state=123, train_size=trainproportion)\n","    print(\"Through train test split. Test proportion:\")\n","    print(testproportion)\n","    return(dtrain,dvalid,test)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vsT0IecPhZk5"},"source":["# Build Pipeline <a name='buildpipe' />\n","\n","Create pipeline objects to perform final data preparation steps for training and inference.\n","\n","Note that cleanup on the training dataset is completed upstream in the [data cleanup notebook](https://github.com/ryanmark1867/end_to_end_deep_learning_liveproject/blob/master/notebooks/data_cleanup.ipynb). \n","- The pipelines only accomplish the subset of preparation that is required for both training and inference\n","- Because the scoring data coming in for inference is forced by the web deployment to avoid the invalid values that the data cleanup notebook deals with, the pipelines don't have to deal with those problems.\n","\n","<a href=#linkanchor>Back to link list</a>"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"id":"TRQFrVUDhZk6","executionInfo":{"status":"ok","timestamp":1666484311294,"user_tz":240,"elapsed":113,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"840a412a-01e1-4b99-95b9-e8cc41354d51"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# master block to invoke pipeline\\n\\n# build fully qualified names for the files for saving the pipelines\\npipeline_path = get_pipeline_path()\\npipeline1_file_name = os.path.join(pipeline_path,\\'sc_delay_pipleline\\'+modifier+\\'.pkl\\')\\npipeline2_file_name = os.path.join(pipeline_path,\\'sc_delay_pipleline_keras_prep\\'+modifier+\\'.pkl\\')\\n\\n# define column lists:\\n# collist,continuouscols,textcols = def_col_lists()\\n\\n# create objects of the pipeline classes\\nfe = fill_empty()\\nec = encode_categorical()\\npk = prep_for_keras_input()\\npk_valid = prep_for_keras_input()\\npk_test = prep_for_keras_input()\\n\\n# need to implement the pipeline in two parts:\\n# 1. fill empty + encode categoricals\\n# 2. prep for Keras\\n# because part 1 needs to be applied to the entire dataset and part 2 to the individual train, validate, and test sets\\n\\n\\nsc_delay_pipeline = Pipeline([(\\'fill_empty\\',fe),(\\'encode_categorical\\',ec)])\\n# need to have distinct pipeline objects for each subset of the dataset: train, validated and test\\nsc_delay_pipeline_keras_prep = Pipeline([(\\'prep_for_keras\\',pk)])\\nsc_delay_pipeline_keras_prep_valid = Pipeline([(\\'prep_for_keras\\',pk_valid)])\\nsc_delay_pipeline_keras_prep_test = Pipeline([(\\'prep_for_keras\\',pk_test)])\\n\\n\\n\\n# provide the value for each parameter of each of the pipeline classes\\n\\nsc_delay_pipeline.set_params(fill_empty__collist = collist, fill_empty__continuouscols = continuouscols,\\n                            fill_empty__textcols = textcols,encode_categorical__col_list = collist)\\nsc_delay_pipeline_keras_prep.set_params(prep_for_keras__collist = collist,\\n                            prep_for_keras__continuouscols = continuouscols,\\n                            prep_for_keras__textcols = textcols)\\nsc_delay_pipeline_keras_prep_valid.set_params(prep_for_keras__collist = collist,\\n                            prep_for_keras__continuouscols = continuouscols,\\n                            prep_for_keras__textcols = textcols)\\nsc_delay_pipeline_keras_prep_test.set_params(prep_for_keras__collist = collist,\\n                            prep_for_keras__continuouscols = continuouscols,\\n                            prep_for_keras__textcols = textcols)\\n\\n# fit the input dataset to the pipeline\\n\\n# first fit the first segment of pipeline on the whole dataset\\nX = sc_delay_pipeline.fit_transform(merged_data)\\nmax_dict = ec.max_dict\\n# then split dataset\\ndump(sc_delay_pipeline, open(pipeline1_file_name,\\'wb\\'))\\ndump(sc_delay_pipeline_keras_prep, open(pipeline2_file_name,\\'wb\\'))\\ndtrain, dvalid, test = get_train_validation_test(X)\\n# then apply second portion of pipeline to each subset\\n# need to have a distinct object for each to prevent first object impacting others\\n\\nX_train_list = sc_delay_pipeline_keras_prep.fit_transform(dtrain)\\nX_valid_list = sc_delay_pipeline_keras_prep_valid.fit_transform(dvalid)\\nX_test_list = sc_delay_pipeline_keras_prep_test.fit_transform(test)\\n\\nprint(\"keras variables defined\")\\nprint(\"X_train_list\",X_train_list)\\n\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["'''\n","# master block to invoke pipeline\n","\n","# build fully qualified names for the files for saving the pipelines\n","pipeline_path = get_pipeline_path()\n","pipeline1_file_name = os.path.join(pipeline_path,'sc_delay_pipleline'+modifier+'.pkl')\n","pipeline2_file_name = os.path.join(pipeline_path,'sc_delay_pipleline_keras_prep'+modifier+'.pkl')\n","\n","# define column lists:\n","# collist,continuouscols,textcols = def_col_lists()\n","\n","# create objects of the pipeline classes\n","fe = fill_empty()\n","ec = encode_categorical()\n","pk = prep_for_keras_input()\n","pk_valid = prep_for_keras_input()\n","pk_test = prep_for_keras_input()\n","\n","# need to implement the pipeline in two parts:\n","# 1. fill empty + encode categoricals\n","# 2. prep for Keras\n","# because part 1 needs to be applied to the entire dataset and part 2 to the individual train, validate, and test sets\n","\n","\n","sc_delay_pipeline = Pipeline([('fill_empty',fe),('encode_categorical',ec)])\n","# need to have distinct pipeline objects for each subset of the dataset: train, validated and test\n","sc_delay_pipeline_keras_prep = Pipeline([('prep_for_keras',pk)])\n","sc_delay_pipeline_keras_prep_valid = Pipeline([('prep_for_keras',pk_valid)])\n","sc_delay_pipeline_keras_prep_test = Pipeline([('prep_for_keras',pk_test)])\n","\n","\n","\n","# provide the value for each parameter of each of the pipeline classes\n","\n","sc_delay_pipeline.set_params(fill_empty__collist = collist, fill_empty__continuouscols = continuouscols,\n","                            fill_empty__textcols = textcols,encode_categorical__col_list = collist)\n","sc_delay_pipeline_keras_prep.set_params(prep_for_keras__collist = collist,\n","                            prep_for_keras__continuouscols = continuouscols,\n","                            prep_for_keras__textcols = textcols)\n","sc_delay_pipeline_keras_prep_valid.set_params(prep_for_keras__collist = collist,\n","                            prep_for_keras__continuouscols = continuouscols,\n","                            prep_for_keras__textcols = textcols)\n","sc_delay_pipeline_keras_prep_test.set_params(prep_for_keras__collist = collist,\n","                            prep_for_keras__continuouscols = continuouscols,\n","                            prep_for_keras__textcols = textcols)\n","\n","# fit the input dataset to the pipeline\n","\n","# first fit the first segment of pipeline on the whole dataset\n","X = sc_delay_pipeline.fit_transform(merged_data)\n","max_dict = ec.max_dict\n","# then split dataset\n","dump(sc_delay_pipeline, open(pipeline1_file_name,'wb'))\n","dump(sc_delay_pipeline_keras_prep, open(pipeline2_file_name,'wb'))\n","dtrain, dvalid, test = get_train_validation_test(X)\n","# then apply second portion of pipeline to each subset\n","# need to have a distinct object for each to prevent first object impacting others\n","\n","X_train_list = sc_delay_pipeline_keras_prep.fit_transform(dtrain)\n","X_valid_list = sc_delay_pipeline_keras_prep_valid.fit_transform(dvalid)\n","X_test_list = sc_delay_pipeline_keras_prep_test.fit_transform(test)\n","\n","print(\"keras variables defined\")\n","print(\"X_train_list\",X_train_list)\n","\n","'''"]},{"cell_type":"code","source":["# Features are\n","# neighbourhood_group\n","# neighbourhood\n","# room_type\n","# minimum_nights\n","# number_of_reviews\n","# reviews_per_month\n","# calculated_host_listings_count\n","\n"],"metadata":{"id":"XFfTDWwlKf-K","executionInfo":{"status":"ok","timestamp":1666484311297,"user_tz":240,"elapsed":111,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# define transforms to apply to the tabular dataset\n","procs = [FillMissing,Categorify]\n","'''\n","# define the dependent variable (y value)\n","dep_var = 'target'\n","# define columns that are continuous / categorical\n","cont,cat = cont_cat_split(merged_data, 1, dep_var=dep_var) \n","print(\"continuous columns are: \",cont)\n","print(\"categorical columns are: \",cat)\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"IpqXXRVf9DQG","executionInfo":{"status":"ok","timestamp":1666484311299,"user_tz":240,"elapsed":104,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"10c3750a-3cb9-4d41-b308-c01cc5a8ddda"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# define the dependent variable (y value)\\ndep_var = \\'target\\'\\n# define columns that are continuous / categorical\\ncont,cat = cont_cat_split(merged_data, 1, dep_var=dep_var) \\nprint(\"continuous columns are: \",cont)\\nprint(\"categorical columns are: \",cat)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# explicitly define cont and cat\n","# Features are\n","# neighbourhood_group\n","# neighbourhood\n","# room_type\n","# minimum_nights\n","# number_of_reviews\n","# reviews_per_month\n","# calculated_host_listings_count\n","dep_var = 'target'\n","cat = ['neighbourhood_group','neighbourhood','room_type']\n","cont = ['minimum_nights','number_of_reviews','reviews_per_month','calculated_host_listings_count']\n","print(\"continuous columns are: \",cont)\n","print(\"categorical columns are: \",cat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bAbTH9rz-dZA","executionInfo":{"status":"ok","timestamp":1666484311303,"user_tz":240,"elapsed":102,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"412e246a-5b81-4cf2-c8b6-7339e456ffdf"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["continuous columns are:  ['minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count']\n","categorical columns are:  ['neighbourhood_group', 'neighbourhood', 'room_type']\n"]}]},{"cell_type":"code","source":["dep_var"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"DinThaT2Cicm","executionInfo":{"status":"ok","timestamp":1666484312453,"user_tz":240,"elapsed":1240,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"522bb642-23db-4361-e180-212db03d70d0"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'target'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["##Define and fit model <a name='modelfit' />\n","- use the unique fastai tabular data capabilities\n","\n","<a href=#linkanchor>Back to link list</a>"],"metadata":{"id":"Y3gWLj4xTURi"}},{"cell_type":"code","source":["# important, if the target column isn't explicitly cast to string, fastai will interpret the \n","# problem as regression rather than classification and accuracy will be bad and static\n","# this is a tricky problem because the values in the target column look like they are string but are integer\n","# clue is that show_batch shows target column values as floating point if you don't case target to string explicitly\n","merged_data['target'] =merged_data.target.astype(str)\n"],"metadata":{"id":"U_EvSjn_LfXc","executionInfo":{"status":"ok","timestamp":1666484312456,"user_tz":240,"elapsed":108,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["merged_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":478},"id":"uoZjsB4RMGVi","executionInfo":{"status":"ok","timestamp":1666484312461,"user_tz":240,"elapsed":111,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"321a066b-4bc4-4361-eaad-6a5f0fc91cce"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     id                                              name  host_id  \\\n","0  2539                Clean & quiet apt home by the park     2787   \n","1  2595                             Skylit Midtown Castle     2845   \n","2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n","3  3831                   Cozy Entire Floor of Brownstone     4869   \n","4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n","\n","     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n","0         John            Brooklyn    Kensington  40.64749  -73.97237   \n","1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n","2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n","3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n","4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n","\n","         room_type  price  minimum_nights  number_of_reviews last_review  \\\n","0     Private room    149               1                  9  2018-10-19   \n","1  Entire home/apt    225               1                 45  2019-05-21   \n","2     Private room    150               3                  0  2019-01-01   \n","3  Entire home/apt     89               1                270  2019-07-05   \n","4  Entire home/apt     80              10                  9  2018-11-19   \n","\n","   reviews_per_month  calculated_host_listings_count  availability_365  \\\n","0               0.21                               6               365   \n","1               0.38                               2               355   \n","2               0.00                               1               365   \n","3               4.64                               1               194   \n","4               0.10                               1                 0   \n","\n","   (latitude, longitude) target  \n","0  (40.64749, -73.97237)      0  \n","1  (40.75362, -73.98377)      1  \n","2   (40.80902, -73.9419)      0  \n","3  (40.68514, -73.95976)      0  \n","4  (40.79851, -73.94399)      0  "],"text/html":["\n","  <div id=\"df-63d5f29b-52f4-4e9a-9b86-eeae97d4b88f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>name</th>\n","      <th>host_id</th>\n","      <th>host_name</th>\n","      <th>neighbourhood_group</th>\n","      <th>neighbourhood</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>room_type</th>\n","      <th>price</th>\n","      <th>minimum_nights</th>\n","      <th>number_of_reviews</th>\n","      <th>last_review</th>\n","      <th>reviews_per_month</th>\n","      <th>calculated_host_listings_count</th>\n","      <th>availability_365</th>\n","      <th>(latitude, longitude)</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2539</td>\n","      <td>Clean &amp; quiet apt home by the park</td>\n","      <td>2787</td>\n","      <td>John</td>\n","      <td>Brooklyn</td>\n","      <td>Kensington</td>\n","      <td>40.64749</td>\n","      <td>-73.97237</td>\n","      <td>Private room</td>\n","      <td>149</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>2018-10-19</td>\n","      <td>0.21</td>\n","      <td>6</td>\n","      <td>365</td>\n","      <td>(40.64749, -73.97237)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2595</td>\n","      <td>Skylit Midtown Castle</td>\n","      <td>2845</td>\n","      <td>Jennifer</td>\n","      <td>Manhattan</td>\n","      <td>Midtown</td>\n","      <td>40.75362</td>\n","      <td>-73.98377</td>\n","      <td>Entire home/apt</td>\n","      <td>225</td>\n","      <td>1</td>\n","      <td>45</td>\n","      <td>2019-05-21</td>\n","      <td>0.38</td>\n","      <td>2</td>\n","      <td>355</td>\n","      <td>(40.75362, -73.98377)</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3647</td>\n","      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n","      <td>4632</td>\n","      <td>Elisabeth</td>\n","      <td>Manhattan</td>\n","      <td>Harlem</td>\n","      <td>40.80902</td>\n","      <td>-73.94190</td>\n","      <td>Private room</td>\n","      <td>150</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>2019-01-01</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>365</td>\n","      <td>(40.80902, -73.9419)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3831</td>\n","      <td>Cozy Entire Floor of Brownstone</td>\n","      <td>4869</td>\n","      <td>LisaRoxanne</td>\n","      <td>Brooklyn</td>\n","      <td>Clinton Hill</td>\n","      <td>40.68514</td>\n","      <td>-73.95976</td>\n","      <td>Entire home/apt</td>\n","      <td>89</td>\n","      <td>1</td>\n","      <td>270</td>\n","      <td>2019-07-05</td>\n","      <td>4.64</td>\n","      <td>1</td>\n","      <td>194</td>\n","      <td>(40.68514, -73.95976)</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5022</td>\n","      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n","      <td>7192</td>\n","      <td>Laura</td>\n","      <td>Manhattan</td>\n","      <td>East Harlem</td>\n","      <td>40.79851</td>\n","      <td>-73.94399</td>\n","      <td>Entire home/apt</td>\n","      <td>80</td>\n","      <td>10</td>\n","      <td>9</td>\n","      <td>2018-11-19</td>\n","      <td>0.10</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>(40.79851, -73.94399)</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63d5f29b-52f4-4e9a-9b86-eeae97d4b88f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-63d5f29b-52f4-4e9a-9b86-eeae97d4b88f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-63d5f29b-52f4-4e9a-9b86-eeae97d4b88f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["merged_data.shape[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"av-IJJRnAa2b","executionInfo":{"status":"ok","timestamp":1666484312463,"user_tz":240,"elapsed":108,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"b9edb091-28a1-4892-fef8-2b35861f0c90"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["48895"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["range((merged_data.shape[0]-5000),merged_data.shape[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yXZHVOdxA78U","executionInfo":{"status":"ok","timestamp":1666484312465,"user_tz":240,"elapsed":99,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"e0bfea44-f9ba-4fde-f286-986b02a7545a"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["range(43895, 48895)"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# define TabularDataLoaders object using the dataframe, the list of pre-processing steps, the categorical and continuous\n","# column lists\n","# valid_idx: the indices to use for the validation set\n","path = '.'\n","#procs = [FillMissing,Categorify, Normalize]\n","procs = [FillMissing,Categorify, Normalize]\n","dls = TabularDataLoaders.from_df(merged_data,path,procs= procs, \n","                                 cat_names= cat, cont_names = cont, \n","                                 y_names = dep_var,\n","                                 valid_idx=list(range((merged_data.shape[0]-10000),merged_data.shape[0])), bs=32)\n","\n"],"metadata":{"id":"DIvJckly9eLH","executionInfo":{"status":"ok","timestamp":1666484312467,"user_tz":240,"elapsed":91,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# display a sample batch\n","dls.valid.show_batch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"qnCPBpPT9gbd","executionInfo":{"status":"ok","timestamp":1666484312469,"user_tz":240,"elapsed":46,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"73cdb7e5-3dcf-4a78-fca6-3c756c80f161"},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>neighbourhood_group</th>\n","      <th>neighbourhood</th>\n","      <th>room_type</th>\n","      <th>minimum_nights</th>\n","      <th>number_of_reviews</th>\n","      <th>reviews_per_month</th>\n","      <th>calculated_host_listings_count</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Manhattan</td>\n","      <td>Hell's Kitchen</td>\n","      <td>Private room</td>\n","      <td>1.000000</td>\n","      <td>18.000000</td>\n","      <td>2.490000e+00</td>\n","      <td>30.000001</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Manhattan</td>\n","      <td>Hell's Kitchen</td>\n","      <td>Private room</td>\n","      <td>1.000000</td>\n","      <td>16.000000</td>\n","      <td>2.220000e+00</td>\n","      <td>30.000001</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Manhattan</td>\n","      <td>Hell's Kitchen</td>\n","      <td>Private room</td>\n","      <td>1.000000</td>\n","      <td>13.000000</td>\n","      <td>1.820000e+00</td>\n","      <td>30.000001</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Brooklyn</td>\n","      <td>Bushwick</td>\n","      <td>Private room</td>\n","      <td>15.000000</td>\n","      <td>0.000001</td>\n","      <td>1.455204e-08</td>\n","      <td>2.000000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Brooklyn</td>\n","      <td>Williamsburg</td>\n","      <td>Private room</td>\n","      <td>19.999999</td>\n","      <td>1.999999</td>\n","      <td>4.200000e-01</td>\n","      <td>1.000000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Queens</td>\n","      <td>Maspeth</td>\n","      <td>Private room</td>\n","      <td>30.000001</td>\n","      <td>0.000001</td>\n","      <td>1.455204e-08</td>\n","      <td>103.000005</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Manhattan</td>\n","      <td>Kips Bay</td>\n","      <td>Entire home/apt</td>\n","      <td>2.000000</td>\n","      <td>1.999999</td>\n","      <td>1.400000e+00</td>\n","      <td>1.000000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Queens</td>\n","      <td>Rosedale</td>\n","      <td>Private room</td>\n","      <td>1.000000</td>\n","      <td>42.000001</td>\n","      <td>5.780000e+00</td>\n","      <td>2.000000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Manhattan</td>\n","      <td>Roosevelt Island</td>\n","      <td>Private room</td>\n","      <td>21.000000</td>\n","      <td>0.999999</td>\n","      <td>2.400000e-01</td>\n","      <td>1.000000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Brooklyn</td>\n","      <td>Clinton Hill</td>\n","      <td>Entire home/apt</td>\n","      <td>3.000000</td>\n","      <td>0.999999</td>\n","      <td>1.600000e-01</td>\n","      <td>1.000000</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}}]},{"cell_type":"code","source":["# define and fit the model\n","#loss_func = CrossEntropyLossFlat(reduction='none')\n","learn = tabular_learner(dls, metrics=accuracy)\n","learn.fit_one_cycle(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"jHOlo07x9kEm","executionInfo":{"status":"ok","timestamp":1666484355922,"user_tz":240,"elapsed":43494,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"7016a302-81a9-406e-88ba-023e9959abdd"},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.412836</td>\n","      <td>0.423849</td>\n","      <td>0.792600</td>\n","      <td>00:19</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.408167</td>\n","      <td>0.397886</td>\n","      <td>0.814100</td>\n","      <td>00:11</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.389448</td>\n","      <td>0.397165</td>\n","      <td>0.815800</td>\n","      <td>00:11</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}}]},{"cell_type":"code","source":["# show the loss function used by the learner\n","learn.loss_func"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0gzD4Ub49o-z","executionInfo":{"status":"ok","timestamp":1666484367546,"user_tz":240,"elapsed":420,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"49f7ee2b-4925-47a6-f8c8-b756c9a7ed4e"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FlattenedLoss of CrossEntropyLoss()"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# show a set of results from the model\n","learn.show_results()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"id":"7UjxHn2-9ugM","executionInfo":{"status":"ok","timestamp":1666484370523,"user_tz":240,"elapsed":433,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"4ad6d155-5809-4543-d53f-b707637eed9a"},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>neighbourhood_group</th>\n","      <th>neighbourhood</th>\n","      <th>room_type</th>\n","      <th>minimum_nights</th>\n","      <th>number_of_reviews</th>\n","      <th>reviews_per_month</th>\n","      <th>calculated_host_listings_count</th>\n","      <th>target</th>\n","      <th>target_pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.0</td>\n","      <td>47.0</td>\n","      <td>3.0</td>\n","      <td>-0.279778</td>\n","      <td>-0.579368</td>\n","      <td>-0.680717</td>\n","      <td>0.107775</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.0</td>\n","      <td>29.0</td>\n","      <td>2.0</td>\n","      <td>-0.279778</td>\n","      <td>-0.291444</td>\n","      <td>0.847106</td>\n","      <td>-0.198527</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.0</td>\n","      <td>29.0</td>\n","      <td>2.0</td>\n","      <td>-0.233155</td>\n","      <td>-0.106350</td>\n","      <td>2.836028</td>\n","      <td>-0.045376</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3.0</td>\n","      <td>95.0</td>\n","      <td>1.0</td>\n","      <td>-0.279778</td>\n","      <td>-0.538236</td>\n","      <td>0.158897</td>\n","      <td>-0.198527</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.0</td>\n","      <td>21.0</td>\n","      <td>2.0</td>\n","      <td>-0.279778</td>\n","      <td>-0.579368</td>\n","      <td>-0.680717</td>\n","      <td>0.056724</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2.0</td>\n","      <td>52.0</td>\n","      <td>1.0</td>\n","      <td>-0.279778</td>\n","      <td>-0.579368</td>\n","      <td>-0.680717</td>\n","      <td>-0.198527</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2.0</td>\n","      <td>92.0</td>\n","      <td>1.0</td>\n","      <td>0.139832</td>\n","      <td>-0.579368</td>\n","      <td>-0.680717</td>\n","      <td>-0.198527</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>3.0</td>\n","      <td>179.0</td>\n","      <td>1.0</td>\n","      <td>-0.233155</td>\n","      <td>-0.476538</td>\n","      <td>2.760325</td>\n","      <td>-0.198527</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2.0</td>\n","      <td>92.0</td>\n","      <td>2.0</td>\n","      <td>-0.186532</td>\n","      <td>-0.579368</td>\n","      <td>-0.680717</td>\n","      <td>-0.147477</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>"]},"metadata":{}}]},{"cell_type":"code","source":["learn.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":763},"id":"uYhrs8x592q0","executionInfo":{"status":"ok","timestamp":1666484382815,"user_tz":240,"elapsed":425,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"7c3dc2af-6a2c-4e97-978f-6ae94b47fde3"},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TabularModel (Input shape: 32 x 3)\n","============================================================================\n","Layer (type)         Output Shape         Param #    Trainable \n","============================================================================\n","                     32 x 4              \n","Embedding                                 24         True      \n","____________________________________________________________________________\n","                     32 x 33             \n","Embedding                                 7326       True      \n","____________________________________________________________________________\n","                     32 x 3              \n","Embedding                                 12         True      \n","Dropout                                                        \n","BatchNorm1d                               8          True      \n","____________________________________________________________________________\n","                     32 x 200            \n","Linear                                    8800       True      \n","ReLU                                                           \n","BatchNorm1d                               400        True      \n","____________________________________________________________________________\n","                     32 x 100            \n","Linear                                    20000      True      \n","ReLU                                                           \n","BatchNorm1d                               200        True      \n","____________________________________________________________________________\n","                     32 x 2              \n","Linear                                    202        True      \n","____________________________________________________________________________\n","\n","Total params: 36,972\n","Total trainable params: 36,972\n","Total non-trainable params: 0\n","\n","Optimizer used: <function Adam at 0x7fc4bdb25950>\n","Loss function: FlattenedLoss of CrossEntropyLoss()\n","\n","Model unfrozen\n","\n","Callbacks:\n","  - TrainEvalCallback\n","  - CastToTensor\n","  - Recorder\n","  - ProgressCallback"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["\n","# print elapsed time to run the notebook\n","print(\"--- %s seconds ---\" % (time.time() - start_time))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F71e5cmdnLM2","executionInfo":{"status":"ok","timestamp":1666484356860,"user_tz":240,"elapsed":49,"user":{"displayName":"Mark Ryan","userId":"08045617267833954278"}},"outputId":"76c22736-f071-48dd-b766-7d29a271707b"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["--- 51.55000948905945 seconds ---\n"]}]}],"metadata":{"kernelspec":{"display_name":"try_tf2","language":"python","name":"try_tf2"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}